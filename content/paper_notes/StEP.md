---
title: "Style-based Encoder Pre-training for Multi-modal Image Synthesis"
date: 2021-10-06
draft: false
---

# Main idea

## Scheme

å°åœ–ç‰‡ä½œä¸€å°å¤šçš„æ¨£æ…‹è½‰æ›

## Problems (motivation)

- ç‚ºäº†è®“æ¨¡å‹èƒ½å°‡è¼¸å…¥è½‰æˆä¸åŒæ¨£æ…‹ï¼Œå¯èƒ½æ¡ç”¨è¤‡é›œçš„æ¨¡å‹ä¾†è¨˜ä½è¼¸å…¥èˆ‡ä¸åŒæ¨£æ…‹é–“çš„é—œè¯æ€§ ï¼ˆæš´åŠ›æ³•ï¼‰
- Mode collapseå•é¡Œ
- é‡åˆ°æ²’çœ‹éçš„é¢¨æ ¼å¯èƒ½è½‰æ›çš„æ•ˆæœå°±ä¸å¦‚é æœŸï¼ˆæ¨¡å‹è½‰æ›ä¸åŒæ¨£æ…‹çš„æˆæœå¥½å£å–æ±ºæ–¼è¨“ç·´æ™‚çš„è¨“ç·´è³‡æ–™é›†ï¼‰

## Relative work

- VAE
- BicycleGAN
- MUNIT-p

## Method

- é è¨“ç·´ä¸€å€‹ä¸éŒ¯çš„é¢¨æ ¼encoderä¾†å°‡è¼¸å…¥çš„é¢¨æ ¼encodeæˆlatent code
- èª¿æ•´ä¸¦å°‹æ‰¾é©åˆçš„loss function (loss termsè¶Šå°‘è¶Šå¥½)

## Result

- åˆæˆçš„çµæœæœ€å¥½
- æ¨¡å‹æˆæ•ˆä¸ä¾è³´ç›®æ¨™è¨“ç·´è³‡æ–™é›†ï¼ˆæ³›ç”¨åº¦æ›´å»£ï¼‰
- æ›´æœ‰æ•ˆæ›´æœ‰èƒ½åŠ›è¡¨é”é¢¨æ ¼ç‰¹å¾µï¼ˆlatent codeï¼‰ï¼Œå°é¢¨æ ¼çš„ä¿çœŸåº¦æé«˜
- ç°¡åŒ–è¨“ç·´ç›®æ¨™ä¸¦åŠ å¿«è¨“ç·´é€Ÿåº¦

---

# Abstract

<aside>
ğŸ’¡ Multi-modal Image-to-image (I2I) translation å¤šæ¨£æ…‹çš„åœ–åƒå°åœ–åƒè½‰æ›

</aside>

### éå»I2Ié‡åˆ°çš„å•é¡Œ

- è¼¸å…¥è¼¸å‡ºçš„ä¸€å°å¤šå°æ‡‰é—œä¿‚
- Mode collapses problem

### éå»è§£æ±ºæ–¹æ³•

- é‡å°å¤šç¨®æ¨£æ…‹çš„è¼¸å‡ºä½¿ç”¨è¤‡é›œçš„æ¨¡å‹é€²è¡Œè¨“ç·´ï¼Œä¾†å› æ‡‰å¤šæ¨£çš„è¼¸å‡ºç¯„ç–‡ çœ‹è‘—çµæœä¾†è¨“ç·´ æš´åŠ›æ³•

### æœ¬è«–æ–‡çš„è§£æ±ºæ–¹æ³•

- å¼·åŒ–åœ–åƒEncoderçš„èƒ½åŠ›ï¼ˆå°é¢¨æ ¼ä½œæ›´é€²éšçš„åˆ†æï¼‰ä¾†å­¸ç¿’æ›´æ½›åœ¨çš„ç©ºé–“ç‰¹å¾µ å°è¼¸å…¥æœ¬è³ªè¨“ç·´

### æœ¬è«–æ–‡çš„æ–¹æ³•æ¦‚å¿µ

- å°‡ I2I è½‰æ›çš„è¡Œç‚ºåˆ†æˆå…©å€‹å·¥ä½œ
    1. pre-trained generic style encoder ( proxy task )
    å­¸ç¿’åœ–ç‰‡çš„åµŒå…¥è³‡è¨Š
    ä»»æ„domainçš„image â†’ ä½ç¶­åº¦çš„é¢¨æ ¼ç©ºé–“è³‡è¨Š
    2. åœ–ç‰‡åˆæˆ

### æœ¬è«–æ–‡çš„å„ªå‹¢

1. æ¨¡å‹ä¸ä¾è³´ç›®æ¨™è¨“ç·´è³‡æ–™é›†ï¼ˆæ³›ç”¨åº¦æ›´å»£ï¼‰
2. æ›´æœ‰æ•ˆæ›´æœ‰èƒ½åŠ›è¡¨é”ç©ºé–“ç‰¹å¾µï¼Œå°é¢¨æ ¼çš„ä¿çœŸåº¦æé«˜
3. ç°¡åŒ–è¨“ç·´ç›®æ¨™ä¸¦åŠ å¿«è¨“ç·´é€Ÿåº¦
4. ä¸åŒloss termå°multi-modal I2Içš„å½±éŸ¿
5. æå‡ºVAEsçš„æ›¿ä»£æ–¹æ¡ˆä¾†å°æœªå—é™åˆ¶çš„ç©ºé–“ç‰¹å¾µé€²è¡Œæ¡æ¨£
6. è·Ÿå…­å€‹å°ç…§çµ„ç›¸æ¯”çµæœæœ€å¥½

# 1. Introduction

### Image-to-image (I2I)

- æ˜¯ä¸€å€‹å°‡åœ–ç‰‡å¾ä¸€å€‹domainè½‰åˆ°å¦å¤–ä¸€å€‹domainçš„ä»»å‹™
e.g. èªæ„åœ–â†’å ´æ™¯ã€æ‰‹ç¹ªç¨¿â†’ç¾å¯¦ç…§ç‰‡
- æ‡‰ç”¨æ–¼è¨±å¤šä½¿ç”¨å ´æ™¯
e.g. è¶…è§£æåº¦æˆåƒã€è‘—è‰²ã€ä¿®è£œ

### I2I çš„ç“¶é ¸

- è¼¸å…¥A â†’ è¼¸å‡ºB é€šå¸¸éƒ½æ˜¯ ä¸€å°å¤š 
$I_i^A\in A$  å¯ä»¥å°æ‡‰åˆ°domain $B$ ä¸­çš„å¤šå€‹è¼¸å‡º
e.g. é‹å­çš„æ‰‹ç¨¿å¯ä»¥å°æ‡‰çš„ä¸åŒé¡è‰²/é¢¨æ ¼çš„æ¨£å¼
- å› ç‚ºI2Iæœ¬èº«æ˜¯ä¸€å°ä¸€å­¸ç¿’ï¼Œå› æ­¤è‹¥è¦æŒ‡å®šoutputç‚ºæŸç¨®ç‰¹å®šå‹æ…‹å‰‡è¦å†å¦å¤–çµ¦ä¸€å€‹input (æŒ‡å®šè½‰æ›çš„mode)
åœ¨è¨“ç·´æœŸé–“å¢åŠ é›œè¨Šå·²ç¶“è¢«è­‰å¯¦ç‚ºç„¡æ•ˆä¸”å¯èƒ½é€ æˆmode collapseå•é¡Œ
    
    <aside>
    ğŸ’¡ mode collapseæ¨¡å¼å´©æ½°ï¼šå†GANè¨“ç·´çš„éç¨‹ä¸­modelåªæœ‰æŠ“åˆ°æŸç¨®ç‰¹å®šé¡åˆ¥çš„ç‰¹å¾µ e.g.æƒ³è¦ç”Ÿæˆå„ç¨®ç¨®é¡çš„è²“å’ªï¼Œä½†è¨“ç·´å®Œåªæœ‰è‹±åœ‹çŸ­æ¯›è²“
    
    </aside>
    
- BicycleGANæå‡ºè§£æ±ºæ¨¡å¼å´©æ½°çš„æ–¹æ³•
    - è¨“ç·´ä¸€å€‹encoder $E$ èˆ‡ I2Iç¿»è­¯çš„åˆæˆç¶²è·¯ï¼Œä¾†é‡å°è¼¸å‡ºç†æ‡‰è©²æœ‰çš„åˆ†ä½ˆé€²è¡Œå­¸ç¿’encodeä¸¦æ”¾åˆ°ä¸€å€‹ç©ºé–“ç‰¹å¾µå‘é‡ $$ $z$ ä¸­
    æœ‰äº†latent vector $z$ ç©ºé–“ç‰¹å¾µå‘é‡ $z$ å°±å¯ä»¥æ›´æ˜ç¢ºçš„çŸ¥é“è¦é¸æ“‡å“ªä¸€å€‹è¼¸å‡ºçµæœç•¶ä½œç›®æ¨™ï¼ˆe.g. $z$ æœƒèªªæ˜¯è‹±åœ‹çŸ­æ¯›è²“ã€æ³¢æ–¯è²“ã€å­ŸåŠ æ‹‰è²“...ç­‰å“ªä¸€å€‹ï¼‰
    - ç„¶å¾Œå†é€éåŸå§‹è¼¸å…¥$A$å’Œ$z$é€²è¡Œåœ–ç‰‡ç¿»è­¯ 
    $G:(A,z)\rightarrow B$

### å¦‚ä½•è®Šæˆunsupervised

- cross-cycle consistency constraint

### æœ¬è«–æ–‡çš„åšæ³•

- å¼±ç›£ç£å¼å­¸ç¿’é è¨“ç·´ç­–ç•¥
encoder $E$ åŠ ä¸Š $I2I$ çš„end-to-end training
- pre-trainingçš„å„ªå‹¢
    1. æ›´æœ‰èƒ½åŠ›å°ç©ºé–“ç‰¹å¾µé€²è¡Œè¡¨ç¤ºæ³•
        1. å¯ä»¥æŠ“åˆ°æ›´ç´°ç¯€çš„é¢¨æ ¼ï¼ˆå¤§é¢¨æ ¼ä¸­é‚„å¯ä»¥æ‰¾åˆ°æ½›åœ¨çš„ç‰¹æ®Šé¢¨æ ¼ï¼‰
        2. é¢¨æ ¼æå–èˆ‡è½‰æ›æ›´æœ‰å¯ä¿¡åº¦
        3. æ›´æœ‰èƒ½åŠ›å°è¤‡é›œé¢¨æ ¼çš„ç‰¹å¾µé€²è¡Œè¡¨ç¤º
    2. æ¨¡å‹ä¸¦ä¸ä¾è³´è¨“ç·´çš„ç›®æ¨™è³‡æ–™é›†ï¼ˆé€šç”¨æ€§æ›´é«˜ã€é©ç”¨æ–¼æ›´å¤šdomainï¼‰
    3. é€éæ›´å°‘çš„lossesä¾†ç°¡åŒ–è¨“ç·´ç›®æ¨™ï¼Œä¸¦æé«˜è¨“ç·´é€Ÿåº¦
    4. æé«˜è¨“ç·´ç©©å®šåº¦å’Œæ•´é«”çš„å“è³ªèˆ‡å¤šæ¨£æ€§
- ä¸éœ€è¦ä»»ä½•æ‰‹å‹•æ¨™ç±¤ï¼ˆå¼±ç›£ç£å¼å­¸ç¿’ï¼‰
åŸºæ–¼é è¨“ç·´VGGæ‰€æä¾›çš„training supervision
- åƒè€ƒåŒ…æ‹¬æ¨™æº–çš„é›»è…¦è¦–è¦ºé è¨“ç·´è³‡æ–™é›†ï¼ˆImageNetï¼‰å’Œéç›£ç£æ˜¯å­¸ç¿’çš„æˆæœä¾†é€²è¡Œfinetuning (transfer learning)
- å¼·èª¿pre-trainingçš„é‡è¦æ€§

### æœ¬è«–æ–‡çš„è²¢ç»

- æå‡ºé è¨“ç·´encoderä¾†å­¸ç¿’ä½ç¶­åº¦gram matricesçš„ç‰¹å¾µï¼Œä»¥æå‡multi-modal I2Iç¿»è­¯çš„æˆæ•ˆ
- è­‰æ˜pre-trained latent embeddingä¸å¿…ä¾è³´è¨“ç·´è³‡æ–™é›†å°±èƒ½é”åˆ°é€šç”¨åŒ–çš„æ•ˆæœ
- æå‡ºä¸åŒlosså°æ–¼multi-modal I2Iç¿»è­¯ç¶²è·¯çš„å½±éŸ¿
- æå‡ºä½¿ç”¨VAEåšç©ºé–“ç‰¹å¾µå–æ¨£çš„æ›¿ä»£æ–¹æ¡ˆ
- æœ¬è«–æ–‡æå‡ºçš„æ–¹æ³•åœ¨é¢¨æ ¼æå–å’Œè½‰æ›ä¸Šéƒ½æ¯”èµ·å¦å¤–å…­å€‹å°ç…§çµ„å¥½ä¸Šè¨±å¤š

# 2. Related work

### Deep generative models

åœ¨éå»çš„ç¶“é©—ä¸­decoderæœƒå­¸ç¿’åœ¨ä¸€å€‹å·²çŸ¥çš„åˆ†ä½ˆ(Gaussian)ä¸­éš¨æ©Ÿå–æ¨£ï¼Œä¸¦å°‡è©²æ¨£æœ¬mapåˆ°å°æ‡‰çš„output image

- **VAEs**
åœ¨latent distributionå’Œoutput imageé–“é€²è¡Œå°å°„(bijection)
- **GANs**
å°‡ä¸€å€‹å¾Gaussianåˆ†ä½ˆå–æ¨£çš„random valuesç›´æ¥æ˜ å°„åˆ°å°æ‡‰çš„imageï¼Œä¸¦ä½¿ç”¨é¡å¤–çš„discriminatoråŠ å¼·ç”Ÿæˆimageçš„çœŸå¯¦æ€§

### Conditional image synthesis

é™„åŠ æ¢ä»¶åˆæˆï¼Œåœ¨inputå¤šé¤µä¸€å€‹flagè®“æ¨¡å‹çŸ¥é“è¼¸å‡ºæ‡‰è©²æ˜¯åœ¨å“ªå€‹domain

- flag: é¡åˆ¥æ¨™ç±¤ã€æ–‡å­—æ•˜è¿°
- cGANs

### Image-to-Image (I2I) translation

å°‡A domainçš„åœ–ç‰‡è½‰æ›æˆB domainçš„åœ–ç‰‡

- inpaintingã€colorizationã€super-resolutionã€rendering(æå¯«)

### Multi-modal I2I translation

éå»çš„I2Iæ¨¡å‹é€šå¸¸éƒ½æ˜¯one-to-one mappingï¼Œè€Œä¸èƒ½å°‡ä¸€å€‹inputå°æ‡‰åˆ°å¤šç¨®ä¸åŒçš„output mode

- BicycleGAN
å­¸ç¿’åˆ°çš„latentæ˜¯å°output domainå’Œæ¢ä»¶é€²è¡Œencodeçš„vector
- BicycleGANçš„åŠ å¼·
ä¸ä½¿ç”¨æˆå°çš„è¨“ç·´è³‡æ–™ï¼Œè€Œæ˜¯ä½¿ç”¨cross-cycle consistency constraintä¾†é™åˆ¶ä¸åŒdomain

<aside>
ğŸ’¡ æœ¬è«–æ–‡æå‡ºä¸€å€‹é è¨“ç·´ç­–ç•¥ï¼Œè®“æ¨¡å‹å­¸ç¿’output domainçš„å¤šæ¨£æ€§ï¼Œä¸¦å°‡output domainçš„ç‰¹å¾µéš±å«åœ¨latentä¸­

</aside>

# 3. Approach

## 3.1 Weakly-supervised encoder pre-training

<aside>
ğŸ’¡ è¨“ç·´ä¸€å€‹å¯ä»¥å°‡é¢¨æ ¼è½‰æ›æˆlatentçš„encoder

</aside>

ç›®æ¨™åœ–ç‰‡ $I_i^B\in B$ å…¶latent style codeç‚º $z_i=E(I_i^B)$

- ç›¸ä¼¼é¢¨æ ¼çš„åœ–ç‰‡æ‡‰è©²æœ‰ç›¸è¿‘çš„ latent space
- ç›¸ç•°é¢¨æ ¼çš„åœ–ç‰‡æ‡‰è©²æœ‰è¿¥ç•°çš„latent space

### å¦‚ä½•åˆ¤æ–·é¢¨æ ¼æ˜¯å¦ç›¸ä¼¼ï¼Ÿ

- ä½¿ç”¨style lossä¾†ä½œç‚ºè·é›¢çŸ©é™£ä¾†åˆ¤æ–·å…©å¼µé¢¨æ ¼æ˜¯å¦ç›¸è¿‘ï¼Œå…¬å¼å¦‚ä¸‹
$L_{style}(\vec{a},\vec{x})=\sum_{l=0}^Lw_lE_l$

$E_l=\frac{1}{4N_l^2M_l^2}\sum_{i,j}(G_{ij}^l-A_{ij}^l)^2$

### å¦‚ä½•è¨“ç·´style encoder

- ä½¿ç”¨tripletè¼¸å…¥ $(I_a,I_p,I_n)$, $I_a$å’Œ$I_p$  é¢¨æ ¼ç›¸ä¼¼è€Œ$I_a$å’Œ$I_n$ é¢¨æ ¼ä¸åŒ(ä½¿ç”¨style lossä¾†è©•æ–·é¢¨æ ¼æ˜¯å¦ç›¸ä¼¼)
- è¨“ç·´ç›®æ¨™å‡½å¼
    
    $\mathcal{L}^{tri}(I_a,I_p,I_n)=\max([\parallel z_a-z_p\parallel^2-\parallel z_a-z_n\parallel^2+\alpha],0)+\lambda \mathcal{L}^{reg}(z_a,z_p,z_n)$
    
    $\mathcal{L^{reg}}(z_a,z_p,z_n)$æ˜¯L2 regression $\lambda\sum_{i=1}^dw_i^2$ å¯ä»¥é¿å…overfittingä¸¦å¢åŠ æ³›ç”¨æ€§
    
- triplet loss?

### æ€éº¼é¸æ“‡triplet?

é¦–å…ˆæœ‰å€‹anchor image $I_a$ä¸¦åˆ†åˆ¥ä½¿ç”¨style lossè¨ˆç®—åœ¨è³‡æ–™é›†ä¸­é¢¨æ ¼èˆ‡$I_a$æœ€æ¥è¿‘çš„ç¾¤$k_c$èˆ‡æœ€é çš„ç¾¤$k_f$ä¸¦å¾æ­¤å…©å€‹æœ€è¿‘æœ€é ç¾¤ä¸­åˆ†åˆ¥å–æ¨£å‡º$I_p$å’Œ$I_n$

ç‚ºäº†é¿å…ç•°å¸¸é¢¨å€‹çš„ç‰¹ä¾‹å½±éŸ¿å–æ¨£ï¼Œåœ¨é¸æ“‡ä¸åŒé¢¨æ ¼çš„ç¾¤æ™‚æœƒé¸æ“‡æœ€å¤§çš„ç¾¤ï¼Œè€Œé¸æ“‡ç›¸ä¼¼é¢¨å€‹çš„ç¾¤å‰‡æ˜¯é¸æ“‡æœ€è¿‘çš„å°ç¾¤

## 3.2 Generator training

ç•¶é è¨“ç·´çš„é¢¨æ ¼æå–encoder $E$ è¨“ç·´å¥½å¾Œé–‹å§‹è¨“ç·´generatorï¼Œæ­¤æ™‚å°‡$E$ çš„åƒæ•¸fix

- ç›®æ¨™é¢¨æ ¼åœ–$I_i^B$
- è©²ç›®æ¨™åœ–çš„é¢¨æ ¼embeddingç‚º $z_i=E(I_i^B)$
- å°‡è¼¸å…¥åœ–é€£åŒç›®æ¨™é¢¨æ ¼ä¸€èµ·æ”¾å…¥generatorä¸­ç”Ÿæˆ $\hat{I_i^B}=G(I_i^A,z_i)$
- åœ¨ä½¿ç”¨ä»¥ä¸‹loss functionä¾†è¡¡é‡è½‰æ›å¾Œçš„é¢¨æ ¼æ˜¯å¦èˆ‡ç›®æ¨™é¢¨æ ¼$B$æ¥è¿‘ï¼Œä¸¦ä½¿ç”¨æ­¤loss functioné€²è¡Œfinetune
$\mathcal{L}^{img}(I_i^B,\hat{I_i^B})=\mathcal{L}_{cGAN}(I_i^B,\hat{I_i^B})+\lambda_{rec}\mathcal{L}_{rec}(I_i^B,\hat{I_i^B})$
    - $\mathcal{L}_{cGAN}$: Least Square GAN
    - $\mathcal{L}_{rec}$: VGG-based perceptual loss

### é¢¨æ ¼å–æ¨£

- **æœ‰ç›®æ¨™é¢¨æ ¼åœ–ï¼š**å¦‚æœæœ‰å·²çŸ¥çš„ç›®æ¨™é¢¨æ ¼åœ–ï¼Œå°±èƒ½é€éencoderä¾†æå–è©²é¢¨æ ¼çš„è³‡è¨Š$z$ï¼Œä¸¦åˆ©ç”¨$z$ä¾†ç”Ÿæˆæ–°çš„åœ–
- **ç„¡ç›®æ¨™é¢¨æ ¼åœ–ï¼š**ä½†å¦‚æœæ²’æœ‰å·²çŸ¥çš„ç›®æ¨™é¢¨æ ¼åœ–ï¼Œè€Œæ˜¯æƒ³åŒlatent distributionä¸­éš¨æ©Ÿå–æ¨£ä¸¦ç›´æ¥è½‰æ›ï¼Œå‰‡éœ€è¦æœ‰å€‹å·²çŸ¥çš„latent distribution
    - åœ¨latent vectorä¸­åŠ å…¥L2 regularizationå¯ä»¥å¼·åˆ¶zero-mean embeddingä¸¦é™åˆ¶latent spaceçš„è®Šç•°æ€§
    - å¦å¤–è¨“ç·´ä¸€å€‹mapperç¶²è·¯$\mathcal{M}$ä¾†å°‡ä¸€å€‹å–®ä½çš„é«˜æ–¯åˆ†ä½ˆæ˜ å°„åˆ°latent distribution æ­¤åšæ³•å¯ä»¥åœ¨style encoderè¨“ç·´ç©ä¸”å¾®èª¿å¾Œé€²è¡Œå¾Œè™•ç†
    $\mathcal{M}$ æ˜¯ä½¿ç”¨nearest-neighbor based Implicit Maximum Likelihood Estimation (IMLE)ä¾†è¨“ç·´
    $\mathcal{M}=\arg\min_{\tilde{\mathcal{M}}}\sum_i\parallel z_i-\tilde{\mathcal{M}}(e_i)\parallel_2^2$
    $e_i=\arg\min_{rj}\parallel z_i-\tilde{\mathcal{M}}(r_j)\parallel_2^2$
    $\{{r_j}\}$æ˜¯å¾unit Gaussian prioréš¨æ©Ÿå–æ¨£çš„é›†åˆ
    - ç‚ºä»€éº¼è¦ä½¿ç”¨mapping network?
        - é¿å…åœ¨å‡è¨­çš„training data set distributionä¸­sampleåˆ°ä¸å¥½çš„image
            
            ![æˆªåœ– 2021-08-23 ä¸‹åˆ1.52.28.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-23_ä¸‹åˆ1.52.28.png)
            
        
        ![æˆªåœ– 2021-08-23 ä¸‹åˆ1.53.29.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-23_ä¸‹åˆ1.53.29.png)
        
        [](https://www.researchgate.net/figure/A-schematic-diagram-of-generative-model-The-unit-Gaussian-distribution-is-mapped-to-a_fig3_339986932)
        
        ![æˆªåœ– 2021-08-23 ä¸‹åˆ1.56.56.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-23_ä¸‹åˆ1.56.56.png)
        
        [](https://arxiv.org/pdf/1812.08985.pdf)
        

## 3.3 Generalizing the pre-training stage

å¾Neural Style Transferæå‡ºçš„Gram matricesè¢«è­‰æ˜èƒ½å¤ æœ‰æ•ˆä¸”å¯ä¿¡ä¾†çš„æŠ“å–ä»»æ„åœ–ç‰‡çš„é¢¨æ ¼ï¼Œéš±å«Gram matriceså¯ä»¥åœ¨å¤§ç¯„åœçš„domainä¸­æº–ç¢ºçš„encodeé¢¨æ ¼ï¼Œä¸¦ä¸”ä¸åªæ˜¯ç‰¹å®šçš„é¢¨æ ¼

å¼•æ­¤åœ¨æœ¬è«–æ–‡ä¸­ä»¥Gram matricesç‚ºåŸºç¤ï¼Œå¸Œæœ›é™¤äº†æœ‰å„ªç§€çš„é¢¨æ ¼ç‰¹å¾µæŠ“å–èƒ½åŠ›ï¼Œé‚„è¦ä¹Ÿåœ¨å¤šå€‹domainé–“æœ‰ä¸éŒ¯çš„æ•ˆæœ

- pre-trainingéšæ®µæ˜¯è®“æ¨¡å‹å…·æœ‰æ³›ç”¨æ€§
è®“æ¨¡å‹çœŸæ­£å­¸ç¿’èªè­˜styleçš„ç‰¹å¾µè€Œéå–®ç´”çš„å°‡styleå€åˆ†cluster
- fine-tuningéšæ®µæ˜¯è®“æ¨¡å‹å°ç‰¹å®šçš„target domainèƒ½æ›´fit

<aside>
ğŸ’¡ æœ¬è«–æ–‡ç™¼ç¾ï¼Œå°inputåšé¢¨æ ¼åˆ†ææ¯”å°output domainåšé¢¨æ ¼åˆ†ææ•ˆæœæ›´å¥½ï¼Œå°¤å…¶æ˜¯åœ¨datasetå¾ˆå°çš„æ™‚å€™

</aside>

# 4. Experimental evaluation

### Dataset

- Space Needle timelapse
    - 2068å°ç…§ç‰‡
    - 8280$\times$1080
    - è¥¿é›…åœ–3å¹´çš„timelapse video
    - [https://hackernoon.com/seattle-3-year-time-lapse-video-from-the-space-needle-9a9e76cfe8bf](https://hackernoon.com/seattle-3-year-time-lapse-video-from-the-space-needle-9a9e76cfe8bf)
- 5å€‹æ¯”è¼ƒç¯„ä¾‹
    1. æ¨™ç±¤ â†’ åœ–ç‰‡
    2. ç©ºæ‹åœ– â†’ åœ°åœ–
    3. edgeåœ– â†’ é‹å­
    4. edgeåœ– â†’ åŒ…åŒ…
    5. æ™šä¸Š â†’ æ—©ä¸Š

### Baselines

- **BicycleGAN v0 (åŸä½œè€…çš„source code)**
- **BicycleGAN v1 (è«–æ–‡ä½œè€…ä½¿ç”¨BicycleGANå¯¦ä½œæœ¬è«–æ–‡æå‡ºçš„æ¶æ§‹)**
- **MUNIT-p**
    - æ‡‰ç”¨å…¶cross-cycle consistency constraintçš„æ¦‚å¿µ
    - è¨“ç·´è¼¸å…¥æ˜¯å…©çµ„è³‡æ–™ $(I_1^A,I_1^B)$ï¼Œ$(I_2^A,I_2^B)$
    - ç®—å‡º1ã€2å…©å€‹é¢¨æ ¼çš„embedding $z_1=E(I_1^B)$ï¼Œ$z_2=E(I_2^B)$
    - åœ¨ä¾†ä½¿ç”¨å…©éšæ®µçš„cyclic reconstruction
        - Step1. ç”Ÿæˆäº¤æ›é¢¨æ ¼çš„åœ–
        $u=G(I_1^A,z_2)$ï¼Œ$v=G(I_2^A,z_1)$
        - Step2. åœ¨è©¦åœ–å¾å…©å€‹æ–°ç”Ÿæˆçš„åœ–å„è‡ªæŠ“å–é¢¨æ ¼embeddingï¼Œä¸¦å†æ¬¡ç”Ÿæˆåœ–ç‰‡(çµæœç†æ‡‰å’Œæœ€åŸå§‹çš„åœ–ä¸€æ¨£)
        $\hat{z_2}=E(u)$ï¼Œ$\hat{z_1}=E(v)$
        $\hat{I_1^B}=G(I_1^A,\hat{z_1})$ï¼Œ$\hat{I_2^B}=G(I_2^A,\hat{z_2})$
        $\hat{I_1^B}$æ‡‰å’Œ$I_1^B$ è¶Šåƒè¶Šå¥½ $\hat{I_2^B}$æ‡‰å’Œ$I_2^B$ è¶Šåƒè¶Šå¥½
    
    ![MUNIT.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal//MUNIT.png)
    

## 4.1. Image reconstruction

### é‡æ§‹åœ–è©•åˆ†æ©Ÿåˆ¶

- PSNR
- AlexNet-based LPIPS metrics åœ–åƒæ„ŸçŸ¥ç›¸ä¼¼åº¦æŒ‡æ¨™
    - ä½¿ç”¨æ·±åº¦ç‰¹å¾µä¾†è¡¡é‡

### å°çµè«–

- åœ¨æœ¬è«–æ–‡æå‡ºçš„æ¶æ§‹ä¸­åœ¨ç¬¬2éšæ®µ(finetuneå‰)å°±å·²é”åˆ°å¤§éƒ¨åˆ†baselineçš„æˆæœ
ç¬¬2éšæ®µå¾Œ(finetuneå®Œ)å°±èƒ½æœ‰å¥½è¨±å¤šçš„æˆæœ
- æœ¬è«–æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥æ›´å¥½çš„é‡æ§‹ç›®æ¨™é¢¨æ ¼åœ–
- è‹¥åœ¨æ¨¡å‹ä¸­æœ‰ä½¿ç”¨VAEæ¶æ§‹å‰‡æœƒå½±éŸ¿è¼¸å‡ºçš„å“è³ª
    - VAEå°æ–¼å™ªè²çš„å¯¬å®¹åº¦è¼ƒé«˜ï¼Œä½†é€£å¸¶å½±éŸ¿å°è¼ƒç´°ç¯€é¢¨æ ¼çš„ç‰¹å¾µæŠ“å–
    - VAEæœƒå­¸è‘—å¿½ç•¥é›œè¨Š(æŠŠæ›´ç´°ç¯€çš„è³‡è¨Šå¿½ç•¥æ‰)
- è‹¥å°‡VAEå¾æ¶æ§‹ä¸­ç§»é™¤å¯ä»¥æ›´å¥½çš„æŠ“å–é¢¨æ ¼ç‰¹å¾µä¸¦ä¸”é‡æ§‹

## 4.2. Style transfer and sampling

å¾é©—è­‰é›†çœ‹åˆ°åŒå€‹å ´æ™¯ä½†ä¸åŒæ°›åœçš„è½‰æ›ï¼ˆæ™´å¤©ã€æ—¥è½ã€éœ§éœ¾ï¼‰

- æ­¤è«–æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥æ›´ç´°ç·»çš„è½‰æ›ï¼Œè€Œä¸åªæ˜¯å…‰å½±è®ŠåŒ–
- éš¨æ©Ÿåœ¨latent distributionä¸­æ¡æ¨£ï¼ˆä¹Ÿå¯ä»¥ä½¿ç”¨mapping$\mathcal{M}$ï¼‰
    - æ¡æ¨£çš„é¢¨æ ¼ä¸åªæ˜¯å–®ç´”åªæœ‰é¡è‰²çš„å·®åˆ¥ï¼Œè€Œæ˜¯æœ‰æ¸…æ¥šçš„å¤©æ°£è®ŠåŒ–ï¼ˆcloudyã€sunnyï¼‰ç­‰ç­‰
        
        ![æˆªåœ– 2021-08-18 ä¸‹åˆ8.53.02.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-18_ä¸‹åˆ8.53.02.png)
        
    - latent vectorçš„å°è®ŠåŒ–å¯èƒ½å°±æ§åˆ¶æŸå€‹è®Šé‡ï¼ˆé›²æœµæ•¸é‡ã€ç©ºæ°£æ¸…æ¥šç¨‹åº¦ï¼‰

## 4.3. Style interpolation

- åœ¨å…©å€‹ç‰¹å®šå ´æ™¯ï¼ˆé¢¨æ ¼ï¼‰çš„latent vectoré–“é€²è¡Œå–æ¨£å¯ä»¥çœ‹åˆ°æ¼¸é€²å¼çš„è®ŠåŒ–
    
    ![æˆªåœ– 2021-08-18 ä¸‹åˆ8.56.08.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-18_ä¸‹åˆ8.56.08.png)
    

## 4.4. Pre-training generalization

### å‡è¨­é¢¨æ ¼embeddingé€šç”¨

æœ¬è«–æ–‡ä½œè€…è¡¨ç¤ºï¼Œåœ¨Neural Style Transferæ–‡ç»ä¸­æå‡ºçš„é¢¨æ ¼çŸ©é™£åœ¨ä¸åŒçš„inputéƒ½æ˜¯é€šç”¨çš„ï¼Œå› æ­¤åœ¨æœ¬è«–æ–‡ä¹Ÿå‡è¨­å¾inputä¸­encodeå‡ºè©²åœ–çš„embeddingï¼ˆlatent vectorï¼‰çš„åšæ³•ä¹Ÿæ˜¯å¯ä»¥é€šç”¨åœ¨ä¸åŒçš„input

### é©—è­‰å‡è¨­

åœ¨ä¸€å€‹æŒ‡å®šçš„ç›®æ¨™è³‡æ–™é›†ä¸‹ï¼Œåˆ†åˆ¥è¨“ç·´generator $G$ ä¸‰æ¬¡ï¼Œå…¶ä¸­é€™ä¸‰æ¬¡éƒ½æ˜¯ä½¿ç”¨ä¸åŒé è¨“ç·´é›†è¨“ç·´å‡ºçš„pre-train style encoder

- Style encoderé…ç½®
    1. ä½¿ç”¨**è½‰æ›å¾Œç›®æ¨™é¢¨æ ¼**çš„åŒå€‹è³‡æ–™é›†é€²è¡Œè¨“ç·´
    2. é¡ä¼¼æ–¼**è½‰æ›å¾Œçš„ç›®æ¨™é¢¨æ ¼ä½†æ˜¯ç‚ºä¸åŒ**çš„è³‡æ–™é›†é€²è¡Œè¨“ç·´
    3. ä½¿ç”¨å®Œå…¨ä¸åŒé¢¨æ ¼çš„è³‡æ–™é›†é€²è¡Œè¨“ç·´
    
    ![æˆªåœ– 2021-08-18 ä¸‹åˆ9.04.27.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-18_ä¸‹åˆ9.04.27.png)
    
- çµè«–
    - ä½¿ç”¨ä¸åŒçš„è³‡æ–™é›†ä¾†è¨“ç·´style encoderçš„çµæœåªæœ‰äº›å¾®çš„å·®åˆ¥
    å› æ­¤ä½¿ç”¨å“ªä¸€å€‹è³‡æ–™é€²è¡Œstyle encoderçš„è¨“ç·´ä¸¦ä¸æ˜¯å¤ªé‡è¦ï¼ˆä»£è¡¨è¨“ç·´å‡ºçš„style encoderæœ‰ä¸€å®šç¨‹åº¦çš„æ³›ç”¨æ€§ï¼‰
    - finetuneå¾Œçš„çµæœéƒ½æœ‰æ›´å¥½ä¸€äº›

## 4.5. Ablative study

![æˆªåœ– 2021-08-23 ä¸‹åˆ1.23.00.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-23_ä¸‹åˆ1.23.00.png)

### å„æ–¹æ³•é…ç½®

- **v1**
    - Bicycle v1
    - MUNIT-p
- **v2**
    - Bicycle v2: ç§»é™¤VAE(è®Šç•°æ•¸éƒ¨åˆ†)
    - MUNIT-p v2: ç§»é™¤VAE(è®Šç•°æ•¸éƒ¨åˆ†)
- **v3**
    - Bicycle v3: ä½¿ç”¨L2æ­£å‰‡ä¾†å–ä»£KL loss
    - MUNIT-p v3: ä½¿ç”¨L2æ­£å‰‡ä¾†å–ä»£KL loss
- **æœ¬è«–æ–‡æ–¹æ³•**
    - Ours v1: åŸºæ–¼MUNIT-p v3å†åŠ ä¸Šä½¿ç”¨pre-trained embedings
    - Ours v2: ç§»é™¤cyclic reconstruction
    - Ours v3: ç§»é™¤random z sampling
    - Ours v4: ç§»é™¤L2æ­£å‰‡

### å°çµè«–

1. ç§»é™¤VAEçš„åœ–ç‰‡åˆæˆçµæœæ›´å¥½
VAEçš„robustå’Œlatent spaceå°æ–¼é¢¨æ ¼çš„è¡¨é”åŠ›æ˜¯ä¸€å€‹tradeoff
2. è¼ƒå°‘çš„loss termsæ•ˆæœæ›´å¥½ï¼ˆé™åˆ¶è¶Šå°‘ï¼‰

## 4.6. Diversity and user study

<aside>
ğŸ’¡ ä½¿ç”¨LPIPSè·é›¢è¨ˆç®—1600å¼µè¼¸å‡ºåœ–çš„å¹³å‡æ•ˆæœ

</aside>

åœ¨100å¼µé©—è­‰è³‡æ–™é›†ä¸‹åˆ†åˆ¥ä½¿ç”¨å…©ç¨®é…ç½®

- å®¢è§€è©•åˆ†
    1. éš¨æ©Ÿé¸æ“‡16å¼µimageä¾†ç•¶ä½œstyle transferçš„ç›®æ¨™é¢¨æ ¼åœ–
    2. éš¨æ©Ÿé¸æ“‡16çµ„é¢¨æ ¼code(mapper network$\mathcal{M}$)
    
    åˆ†åˆ¥å°‡16å€‹ç›®æ¨™é¢¨æ ¼æ‡‰ç”¨åœ¨100å¼µé©—è­‰è³‡æ–™åœ–ç‰‡ä¸­ï¼Œä¸¦è¨ˆç®—LPIPSçš„å¹³å‡å€¼
    
- ä¸»è§€è©•åˆ†
    - 30ä½åƒèˆ‡è€…
    - æ¯ä½åƒèˆ‡è€…çµ¦äºˆå››å¼µåœ–
        1. é‹å­é‰›ç­†ç¨¿
        2. ç›®æ¨™é¢¨æ ¼åœ–ç‰‡
        3. å…©å¼µé¢¨æ ¼è½‰æ›å¾Œçš„è¼¸å‡º
    - ä½¿ç”¨è€…è¦é¸å‡ºå“ªä¸€å¼µè¼¸å‡ºæ›´ç‚ºæ“¬çœŸï¼Œè‹¥çš†ç‚ºæ“¬çœŸå‰‡å“ªä¸€å¼µè¼¸å‡ºçš„é¢¨æ ¼è½‰æ›çš„æ›´ç‚ºç›¸ä¼¼
    - ä»¥Ours v4ä½œç‚ºä¸»è¦æ¯”è¼ƒå°è±¡ï¼Œåˆ†åˆ¥èˆ‡å…¶ä»–æ–¹æ³•åšæ¯”è¼ƒ
    - Ours v2çš„User preferenceåˆ†æ•¸è¼ƒä½æ˜¯å› ç‚ºæœ‰æ¯”è¼ƒå¤šçš„å‡å½±

![æˆªåœ– 2021-08-23 ä¸‹åˆ1.20.23.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-23_ä¸‹åˆ1.20.23.png)

![æˆªåœ– 2021-08-23 ä¸‹åˆ1.20.50.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-23_ä¸‹åˆ1.20.50.png)

## 4.7. Visualizing pre-trained embeddings

å°‡latent spaceè¦–è¦ºåŒ–å¯ä»¥çœ‹åˆ°ç›¸è¿‘é¢¨æ ¼çš„åœ–ç‰‡æœƒè¢«åˆ†åœ¨åŒçš„clusterä¸­

![æˆªåœ– 2021-08-20 ä¸‹åˆ8.19.32.png](./Style-based%20Encoder%20Pre-training%20for%20Multi-modal/æˆªåœ–_2021-08-20_ä¸‹åˆ8.19.32.png)

# 5. Conclusion

- åœ¨æœ‰å¤šå€‹domainè½‰æ›éœ€æ±‚çš„æ‡‰ç”¨ä¸‹ï¼Œé€šç”¨ç¨‹åº¦éå¸¸çš„å¥½
- å› ç‚ºloss functionè®Šå¾—ç°¡å–®ï¼Œè¨“ç·´æ›´å¿«ä¹Ÿèƒ½æ›´å¥½çš„æŠ“å–é¢¨æ ¼ç‰¹å¾µ
- åˆ†åˆ¥åˆ†æäº†å„å€‹loss termçš„æ„ç¾©
- æŒ‡å‡ºVAEåœ¨å¤šæ¨¡æ…‹è½‰æ›æ‡‰ç”¨æ™‚æœƒé¢è‡¨çš„ç“¶é ¸